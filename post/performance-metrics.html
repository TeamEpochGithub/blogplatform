<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><meta name="next-head-count" content="2"/><link rel="preload" href="/_next/static/css/7888042adeb60ba7.css" as="style"/><link rel="stylesheet" href="/_next/static/css/7888042adeb60ba7.css" data-n-g=""/><link rel="preload" href="/_next/static/css/84692d296c4e17c9.css" as="style"/><link rel="stylesheet" href="/_next/static/css/84692d296c4e17c9.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-5cd94c89d3acac5f.js"></script><script src="/_next/static/chunks/webpack-4dc2921e155e6a75.js" defer=""></script><script src="/_next/static/chunks/framework-5f4595e5518b5600.js" defer=""></script><script src="/_next/static/chunks/main-154fb50724edcf59.js" defer=""></script><script src="/_next/static/chunks/pages/_app-ab1746b4453cdd77.js" defer=""></script><script src="/_next/static/chunks/769-f90ea21a50d11f43.js" defer=""></script><script src="/_next/static/chunks/pages/post/%5Bslug%5D-603f4ac6c13a4d80.js" defer=""></script><script src="/_next/static/TkC8NIFVtHPKqN7ziD4b1/_buildManifest.js" defer=""></script><script src="/_next/static/TkC8NIFVtHPKqN7ziD4b1/_ssgManifest.js" defer=""></script><script src="/_next/static/TkC8NIFVtHPKqN7ziD4b1/_middlewareManifest.js" defer=""></script></head><body><div id="__next" data-reactroot=""><div class="container text-white mx-auto px-10 mb-8"><div class="mt-4 w-full inline-block py-8"><div class="md:float-left block"><img height="150" width="150" class="ml-6 hover:scale-110 transition duration-500" src="./epochwhite.png"/></div><div class="hidden space-x-8 md:contents text-gray-500"><img height="30px" width="30px" class="md:float-right mt-4 -translate-x-6 align-middle ml-4 font-semibold cursor-pointer hover:scale-110 transition duration-500" src="https://img.icons8.com/ios-glyphs/30/ffffff/instagram-new.png"/><img height="30px" width="30px" class="md:float-right mt-4 -translate-x-6 align-middle ml-4 font-semibold cursor-pointer hover:scale-110 transition duration-500" src="https://img.icons8.com/ios-glyphs/30/ffffff/linkedin.png"/><span class="md:float-right -translate-x-6 mt-4 align-middle text-xl font-semibold cursor-pointer hover:scale-110 font-semibold transition duration-500 hover:text-transparent hover:bg-clip-text bg-gradient-to-r hover:from-emerald-300 hover:to-blue-400 hover:font-semibold">FAQ</span><span class="md:float-right -translate-x-6 mt-4 align-middle text-xl font-semibold cursor-pointer hover:scale-110 font-semibold transition duration-500 hover:text-transparent hover:bg-clip-text bg-gradient-to-r hover:from-emerald-300 hover:to-blue-400 hover:font-semibold">News</span><span class="md:float-right -translate-x-6 mt-4 align-middle text-xl font-semibold cursor-pointer hover:scale-110 transition duration-500 hover:text-transparent hover:bg-clip-text bg-gradient-to-r hover:from-emerald-300 hover:to-blue-400 hover:font-semibold text-4xl font-semibold">BlogPage</span></div></div></div><div class="container mx-auto px-10 mb-8"><div class="grid grid-cols-1 lg:grid-cols-12 gap-12"><div class="col-span-1 lg:col-span-8 mt-16"><div class="text-lg translate-x-6 lg:p-8 pb-12 mb-36 -mt-12 text-justify"><h1 class="mb-4 text-center text-5xl text-white font-bold -mt-12">Performance Metrics: How to measure the success of an algorithm</h1><div class="hidden md:flex items-center justify-center mb-8 lg:mb-0 lg:w-auto mr-8 items-center"><img alt="Kerem Bayraktar" height="30px" width="30px" class="rounded-full" src="https://media.graphcms.com/IOTagUWRP6ti05SqT0fK"/><p class="inline align-middle text-gray-500 ml-2 font-medium text-lg">Kerem Bayraktar</p><svg xmlns="http://www.w3.org/2000/svg" class="h-6 w-6 inline ml-8 mr-2 text-emerald-500" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M8 7V3m8 4V3m-9 8h10M5 21h14a2 2 0 002-2V7a2 2 0 00-2-2H5a2 2 0 00-2 2v12a2 2 0 002 2z"></path></svg><span class="align-middle text-gray-500">Mar 16, 2022</span></div><div class="text-white mt-8"><p class="mb-8">The search for the <!-- -->, motion capture of <!-- -->, and exchange rate <!-- --> for foreign currencies. What do these have in common? The answer is AI competitions, in which their contestants helped with their unique solutions to raise the level for current technologies. Ranging from Netflix’s recommender system to driverless car technologies, the competitive nature of these events helped to shape the future of these breakthroughs with one quite attractive goal: to win. But what does it mean to be a true winner of an AI competition, or rather a more natural question, how can you measure the success of an algorithm? </p><p class="mb-8"></p><div class="hidden md:flex items-center justify-center mb-8 lg:mb-0 lg:w-auto mr-8 items-center"><img alt="binaryclassification.png" height="239" width="257" src="https://media.graphcms.com/ioMuttQaRwTdNJq3fdwZ" class="mb-2"/></div><p class="mb-8"><em>Example of a binary classification task, </em> </p><p class="mb-8">Let’s start with a simpler case of Machine Learning with binary classification, where the algorithm needs to classify the case between two classes. To make things more familiar, we can go through the example of testing for the presence of COVID-19 virus where we are trying to develop an algorithm that “guesses” whether the person has the disease or not, as a precautionary risk evaluation. We divide our problem into two basic main classes of two points of suspicion: </p><p class="mb-8">Our machine will predict with its algorithm based on several factors (what we call the “features”) such as age, gender, symptoms, blood readings etc., and classify the specific case into one of these classification classes. How would we test the effectiveness of this algorithm? </p><p class="mb-8">Your first intuitive answer could be that the cases where the machine guessed it right over the total number of cases, practically calculating its accuracy percentage. This accuracy standard would not be as effective for imbalanced training datasets. If 95 of the 100 patients are positive, an algorithm that just guesses everyone as positive would be 95% accurate, although with another set of data it would be completely useless. Furthermore, this accuracy metric would overlook the importance of “right” and “wrong” answers. A COVID-positive patient that’s overlooked as negative is far more dangerous for the community than a COVID-negative patient that was mistaken as positive.  Therefore, we need to draw clear boundaries between these cases, in a structure where use the technical term Confusion Matrix to differentiate between:</p><p class="mb-8"><em>Example of a </em></p><p class="mb-8"></p><div class="hidden md:flex items-center justify-center mb-8 lg:mb-0 lg:w-auto mr-8 items-center"><img alt="precisionrecall.png" height="1364" width="750" src="https://media.graphcms.com/LocWPYfWSuGRaV9jF76D" class="mb-2"/></div><p class="mb-8">With the addition of these concepts, our concept of accuracy should change accordingly as well. We use two additional notions as helpers that make use of these keywords. </p><p class="mb-8"><b>Precision</b> measures the number of patients flagged as COVID-positive that were correctly classified to the total number of positive classifications (<em>What percentage of positive identifications were actually correct?</em>). In that sense, it helps us to determine how good the algorithm is with the guessing of the positive cases.</p><p class="mb-8"> <b>Recall</b>, on the other hand measures the ratio of the correctly guessed positive cases to the amount of total positive cases(What percentage of actual positives were correctly identified?). </p><p class="mb-8"></p><div class="hidden md:flex items-center justify-center mb-8 lg:mb-0 lg:w-auto mr-8 items-center"><img alt="recallprecision.jpg" height="112" width="520" src="https://media.graphcms.com/qfInrUzVQkiKePB8LWjn" class="mb-2"/></div><p class="mb-8">The distinction is that recall works with total (true) positive cases, which includes the overlooked false negatives, whereas precision is about the total (predicted) positive classifications. </p><p class="mb-8">With these notions, we can use a better version of accuracy, by taking both into account. We can do this measurement with a method called <!-- -->, where we take the harmonic mean of the precision and recall so that we can take into account both of these measurements. One thing to note is that the importance of precision and recall is the same in this case. As an additional measure, it’s possible to add an offset or what we call a “real factor” β, such that recall will be considered β times as important as precision.</p><p class="mb-8"></p><div class="hidden md:flex items-center justify-center mb-8 lg:mb-0 lg:w-auto mr-8 items-center"><img alt="Fscore.jpg" height="55" width="523" src="https://media.graphcms.com/9U12kjPQ5moB9Ig9dn8W" class="mb-2"/></div><p class="mb-8">Another way to approach the binary classification issue is the <!-- -->. This curve depends on <b>True Positive Rate</b> and <b>False Positive Rate</b>, where the former is the synonym for Recall and the latter is its counterpart. A ROC curve plots the TPR vs. FPR in practice for different classification thresholds, in order to display the different ratios with differing values. In practice, it’s a way to separate the noise from the actual accuracy. </p><p class="mb-8"></p><div class="hidden md:flex items-center justify-center mb-8 lg:mb-0 lg:w-auto mr-8 items-center"><img alt="truefalse.jpg" height="106" width="537" src="https://media.graphcms.com/imqq0Y3SGWpICMJkbMaL" class="mb-2"/></div><p class="mb-8">However, to compute all values on the ROC curve is quite inefficient from the computational perspective, hence the need for the AUC curve, an acronym for “<b>Area Under the (ROC) Curve</b>”. It is a way to quantify the performance of the accumulated results across all possible thresholds by taking the integral of the ROC curve.</p><p class="mb-8"><em>Example of an </em></p><p class="mb-8"> In a different way, it’s the ability of the algorithm to distinguish between classes. An AUC value of 1 indicates perfect prediction whereas 0 indicates imperfect. The desirable parts of AUC-ROC are that it’s scale-invariant, and also doesn’t depend on the classification threshold. </p><p class="mb-8">What about problems where the algorithm doesn’t necessarily decide per each object, but rather predicts a value by using a continuous line? We call these kinds of examples “<b>regression models</b>”, where it’s a way of predictive modeling with the previous data to approximate. In this case, the distance from the predicted value to the original value plays an important role as now it matters to us how “wrong” we are. A good and simple starting point is the “<b>Mean Absolute Error</b>”, which is the average of the difference between the expected and the original values. Unfortunately, it’s complicated to write efficient pieces of linear programming as the numbers get bigger and bigger, so the preferred way of using it is through the “<b>Mean Squared Error</b>”. This way, the numbers that we are dealing with are smaller and easier to compute (working with square roots instead), as well as to conserve the meaning behind the concept itself. Minimizing this is another blog’s issue, though.</p><p class="mb-8"></p><div class="hidden md:flex items-center justify-center mb-8 lg:mb-0 lg:w-auto mr-8 items-center"><img alt="linearregression.jpg" height="720" width="1280" src="https://media.graphcms.com/PothKbYQkOpnjeW0LjUp" class="mb-2"/></div><p class="mb-8"><em>Example of a </em></p><p class="mb-8">As you can see, there are plenty of ways to measure how good an algorithm is, even for the simplest versions of classifications and predictions. Therefore, it is up to the AI competition organizers to go with the one that’s the most suitable to their expectations, importance values, and the context of the problem.  Which then determines the success of the algorithm, bringing us full circle.</p><p class="mb-8">Sources:</p><p class="mb-8"></p><p class="mb-8"></p><p class="mb-8"></p><p class="mb-8"></p><p class="mb-8"></p><p class="mb-8"></p><div class="hidden md:flex items-center justify-center mb-8 lg:mb-0 lg:w-auto mr-8 items-center"><img alt="roc-auc.png" height="708" width="1000" src="https://media.graphcms.com/Po53jbTuQsKqZJOvxVii" class="mb-2"/></div><p class="mb-8"></p></div></div><div class="scale-90 -translate-y-28 text-center p-12 relative rounded-lg bg-black bg-opacity-20"><div class="absolute left-0 right-0 -top-14"><span style="box-sizing:border-box;display:inline-block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:relative;max-width:100%"><span style="box-sizing:border-box;display:block;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;max-width:100%"><img style="display:block;max-width:100%;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0" alt="" aria-hidden="true" src="data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%27110%27%20height=%27110%27/%3e"/></span><img alt="Kerem Bayraktar" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="intrinsic" class="align-middle rounded-full" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%"/><noscript><img alt="Kerem Bayraktar" src="https://media.graphcms.com/IOTagUWRP6ti05SqT0fK" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%" class="align-middle rounded-full" loading="lazy"/></noscript></span></div><h3 class="text-white mt-4 mb-4 text-xl font-bold">Kerem Bayraktar</h3><p class="text-gray-400 text-ls">Computer scientist currently student at TU Delft.</p></div><div class="grid grid-cols-1 lg:grid-cols-8 gap-12 mb-8"></div><div class="scale-90 bg-transparent opacity-80 -mt-10 border-double border-4 border-gray-500 rounded-lg p-8 pb-12 mb-8"><h3 class="text-2xl text-white font-semibold pb-4">Something to share?</h3><div class="grid grid-cols-1 gap-4 mb-4"><textarea class="p-4 outline-none w-full rounded-lg h-40 focus:ring-2 focus:ring-gray-200 bg-transparent text-gray-100 border border-gray-500 rounded-lg" name="comment" placeholder="Comment"></textarea></div><div class="grid grid-cols-1 gap-4 mb-4"><input type="text" class="py-2 px-4 outline-none w-full rounded-lg focus:ring-2 focus:ring-gray-200 bg-transparent text-gray-200 border border-gray-500 rounded-lg" placeholder="Name" name="name"/><input type="email" class="py-2 px-4 outline-none w-full rounded-lg focus:ring-2 focus:ring-gray-200 bg-transparent text-gray-200 border border-gray-500 rounded-lg" placeholder="Email" name="email"/></div><div class="grid grid-cols-1 gap-4 mb-4"><div><input type="checkbox" id="storeData" name="storeData" value="true"/><label class="text-gray-500 cursor-pointer ml-1" for="storeData"> Save my name and email in this browser for the next time I comment.</label></div></div><div class="mt-8"><button type="button" class="transition duration-500 ease inline-block bg-gradient-to-r from-blue-600 to-emerald-500 hover:scale-105 text-lg font-medium rounded-full text-white px-8 py-3 cursor-pointer">Publish Comment</button></div></div></div><div class="col-span-1 lg:col-span-4 mt-8"><div class="relative lg:sticky top-8"><div class="bg-transparent opacity-80 p-8 mb-8"><h3 class="text-xl mb-8 text-white font-semibold border-b border-b border-gray-500 pb-3">Related Posts</h3></div><div class="text-lg bg-transparent opacity-80 p-8 -mt-16 mb-8 pb-6"><h3 class="text-xl text-white mb-8 font-semibold pb-3 border-b border-gray-500">Categories</h3></div></div></div></div></div><div class="container mx-auto px-10 mb-8 mt-20"><div class="border-t-2 w-full inline-block border-gray-500 py-10"><div class="text-center cursor-pointer text-white"><div>Built and designed by Team Epoch. </div><div>All rights reserved. ©</div></div></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"title":"Performance Metrics: How to measure the success of an algorithm","excerpt":"The search for the Higgs boson, motion capture of Xbox Kinect, and exchange rate predictions for foreign currencies. What do these have in common?","featuredImage":{"url":"https://media.graphcms.com/Y2cfb7URUGsrJ3TAfIaQ"},"author":{"name":"Kerem Bayraktar","bio":"Computer scientist currently student at TU Delft.","photo":{"url":"https://media.graphcms.com/IOTagUWRP6ti05SqT0fK"}},"createdAt":"2022-03-16T15:18:10.860139+00:00","slug":"performance-metrics","content":{"raw":{"children":[{"type":"paragraph","children":[{"text":"The search for the "},{"href":"https://www.symmetrymagazine.org/article/july-2014/the-machine-learning-community-takes-on-the-higgs","type":"link","children":[{"text":"Higgs boson"}],"openInNewTab":false},{"text":", motion capture of "},{"href":"https://venturebeat.com/2011/12/12/kaggle-competition-microsoft-kinect-learn-new-gestures/","type":"link","children":[{"text":"Xbox Kinect"}],"openInNewTab":false},{"text":", and exchange rate "},{"href":"https://www.imperial.ac.uk/media/imperial-college/faculty-of-natural-sciences/department-of-mathematics/math-finance/Nielsen_Laurids-Gert_01424460.pdf","type":"link","children":[{"text":"predictions"}],"openInNewTab":false},{"text":" for foreign currencies. What do these have in common? The answer is AI competitions, in which their contestants helped with their unique solutions to raise the level for current technologies. Ranging from Netflix’s recommender system to driverless car technologies, the competitive nature of these events helped to shape the future of these breakthroughs with one quite attractive goal: to win. But what does it mean to be a true winner of an AI competition, or rather a more natural question, how can you measure the success of an algorithm? "}]},{"type":"paragraph","children":[{"text":""}]},{"src":"https://media.graphcms.com/ioMuttQaRwTdNJq3fdwZ","type":"image","title":"binaryclassification.png","width":257,"handle":"ioMuttQaRwTdNJq3fdwZ","height":239,"children":[{"text":""}],"mimeType":"image/png"},{"type":"paragraph","children":[{"text":"Example of a binary classification task, ","italic":true},{"href":"https://medium.com/@tarunnanduri/artificial-neural-networks-perceptron-85f1b7482feb","type":"link","children":[{"text":"taken from","italic":true}],"openInNewTab":false},{"text":" "}]},{"type":"paragraph","children":[{"text":"Let’s start with a simpler case of Machine Learning with binary classification, where the algorithm needs to classify the case between two classes. To make things more familiar, we can go through the example of testing for the presence of COVID-19 virus where we are trying to develop an algorithm that “guesses” whether the person has the disease or not, as a precautionary risk evaluation. We divide our problem into two basic main classes of two points of suspicion: "}]},{"type":"numbered-list","children":[{"type":"list-item","children":[{"type":"list-item-child","children":[{"text":"The person is carrying the virus."}]}]},{"type":"list-item","children":[{"type":"list-item-child","children":[{"text":"The person is not carrying the virus."}]}]}]},{"type":"paragraph","children":[{"text":"Our machine will predict with its algorithm based on several factors (what we call the “features”) such as age, gender, symptoms, blood readings etc., and classify the specific case into one of these classification classes. How would we test the effectiveness of this algorithm? "}]},{"type":"paragraph","children":[{"text":"Your first intuitive answer could be that the cases where the machine guessed it right over the total number of cases, practically calculating its accuracy percentage. This accuracy standard would not be as effective for imbalanced training datasets. If 95 of the 100 patients are positive, an algorithm that just guesses everyone as positive would be 95% accurate, although with another set of data it would be completely useless. Furthermore, this accuracy metric would overlook the importance of “right” and “wrong” answers. A COVID-positive patient that’s overlooked as negative is far more dangerous for the community than a COVID-negative patient that was mistaken as positive.  Therefore, we need to draw clear boundaries between these cases, in a structure where use the technical term Confusion Matrix to differentiate between:"}]},{"type":"paragraph","children":[{"text":"Example of a ","italic":true},{"href":"https://towardsdatascience.com/confusion-matrix-for-your-multi-class-machine-learning-model-ff9aa3bf7826","type":"link","children":[{"text":"Confusion Matrix","italic":true}],"openInNewTab":false},{"text":""}]},{"type":"bulleted-list","children":[{"type":"list-item","children":[{"type":"list-item-child","children":[{"text":"True Positive: The model "},{"bold":true,"text":"correctly"},{"text":" predicts the "},{"bold":true,"text":"positive"},{"text":" class"}]}]},{"type":"list-item","children":[{"type":"list-item-child","children":[{"text":"False Positive: The model "},{"bold":true,"text":"incorrectly"},{"text":" predicts the "},{"bold":true,"text":"positive"},{"text":" class (positive for COVID-negative person)"}]}]},{"type":"list-item","children":[{"type":"list-item-child","children":[{"text":"True Negative: The model "},{"bold":true,"text":"correctly"},{"text":" predicts the "},{"bold":true,"text":"negative"},{"text":" class"}]}]},{"type":"list-item","children":[{"type":"list-item-child","children":[{"text":"False Negative: The model "},{"bold":true,"text":"incorrectly"},{"text":" predicts the "},{"bold":true,"text":"negative"},{"text":" class (negative for COVID-positive person)"}]}]}]},{"type":"paragraph","children":[{"text":""}]},{"src":"https://media.graphcms.com/LocWPYfWSuGRaV9jF76D","type":"image","title":"precisionrecall.png","width":750,"handle":"LocWPYfWSuGRaV9jF76D","height":1364,"children":[{"text":""}],"mimeType":"image/png"},{"type":"paragraph","children":[{"text":"With the addition of these concepts, our concept of accuracy should change accordingly as well. We use two additional notions as helpers that make use of these keywords. "}]},{"type":"paragraph","children":[{"bold":true,"text":"Precision"},{"text":" measures the number of patients flagged as COVID-positive that were correctly classified to the total number of positive classifications ("},{"text":"What percentage of positive identifications were actually correct?","italic":true},{"text":"). In that sense, it helps us to determine how good the algorithm is with the guessing of the positive cases."}]},{"type":"paragraph","children":[{"text":" "},{"bold":true,"text":"Recall"},{"text":", on the other hand measures the ratio of the correctly guessed positive cases to the amount of total positive cases(What percentage of actual positives were correctly identified?). "}]},{"type":"paragraph","children":[{"text":""}]},{"src":"https://media.graphcms.com/qfInrUzVQkiKePB8LWjn","type":"image","title":"recallprecision.jpg","width":520,"handle":"qfInrUzVQkiKePB8LWjn","height":112,"children":[{"text":""}],"mimeType":"image/jpeg"},{"type":"paragraph","children":[{"text":"The distinction is that recall works with total (true) positive cases, which includes the overlooked false negatives, whereas precision is about the total (predicted) positive classifications. "}]},{"type":"paragraph","children":[{"text":"With these notions, we can use a better version of accuracy, by taking both into account. We can do this measurement with a method called "},{"href":"https://en.wikipedia.org/wiki/F-score","type":"link","children":[{"bold":true,"text":"F-score"}],"openInNewTab":false},{"text":", where we take the harmonic mean of the precision and recall so that we can take into account both of these measurements. One thing to note is that the importance of precision and recall is the same in this case. As an additional measure, it’s possible to add an offset or what we call a “real factor” β, such that recall will be considered β times as important as precision."}]},{"type":"paragraph","children":[{"text":""}]},{"src":"https://media.graphcms.com/9U12kjPQ5moB9Ig9dn8W","type":"image","title":"Fscore.jpg","width":523,"handle":"9U12kjPQ5moB9Ig9dn8W","height":55,"children":[{"text":""}],"mimeType":"image/jpeg"},{"type":"paragraph","children":[{"text":"Another way to approach the binary classification issue is the "},{"href":"https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc","type":"link","children":[{"bold":true,"text":"AUC-ROC curve"}],"openInNewTab":false},{"text":". This curve depends on "},{"bold":true,"text":"True Positive Rate"},{"text":" and "},{"bold":true,"text":"False Positive Rate"},{"text":", where the former is the synonym for Recall and the latter is its counterpart. A ROC curve plots the TPR vs. FPR in practice for different classification thresholds, in order to display the different ratios with differing values. In practice, it’s a way to separate the noise from the actual accuracy. "}]},{"type":"paragraph","children":[{"text":""}]},{"src":"https://media.graphcms.com/imqq0Y3SGWpICMJkbMaL","type":"image","title":"truefalse.jpg","width":537,"handle":"imqq0Y3SGWpICMJkbMaL","height":106,"children":[{"text":""}],"mimeType":"image/jpeg"},{"type":"paragraph","children":[{"text":"However, to compute all values on the ROC curve is quite inefficient from the computational perspective, hence the need for the AUC curve, an acronym for “"},{"bold":true,"text":"Area Under the (ROC) Curve"},{"text":"”. It is a way to quantify the performance of the accumulated results across all possible thresholds by taking the integral of the ROC curve."}]},{"type":"paragraph","children":[{"text":"Example of an ","italic":true},{"href":"https://towardsdatascience.com/understanding-auc-roc-curve-68b2303cc9c5","type":"link","children":[{"text":"AUC-ROC Curve","italic":true}],"openInNewTab":false},{"text":""}]},{"type":"paragraph","children":[{"text":" In a different way, it’s the ability of the algorithm to distinguish between classes. An AUC value of 1 indicates perfect prediction whereas 0 indicates imperfect. The desirable parts of AUC-ROC are that it’s scale-invariant, and also doesn’t depend on the classification threshold. "}]},{"type":"paragraph","children":[{"text":"What about problems where the algorithm doesn’t necessarily decide per each object, but rather predicts a value by using a continuous line? We call these kinds of examples “"},{"bold":true,"text":"regression models"},{"text":"”, where it’s a way of predictive modeling with the previous data to approximate. In this case, the distance from the predicted value to the original value plays an important role as now it matters to us how “wrong” we are. A good and simple starting point is the “"},{"bold":true,"text":"Mean Absolute Error"},{"text":"”, which is the average of the difference between the expected and the original values. Unfortunately, it’s complicated to write efficient pieces of linear programming as the numbers get bigger and bigger, so the preferred way of using it is through the “"},{"bold":true,"text":"Mean Squared Error"},{"text":"”. This way, the numbers that we are dealing with are smaller and easier to compute (working with square roots instead), as well as to conserve the meaning behind the concept itself. Minimizing this is another blog’s issue, though."}]},{"type":"paragraph","children":[{"text":""}]},{"src":"https://media.graphcms.com/PothKbYQkOpnjeW0LjUp","type":"image","title":"linearregression.jpg","width":1280,"handle":"PothKbYQkOpnjeW0LjUp","height":720,"children":[{"text":""}],"mimeType":"image/jpeg"},{"type":"paragraph","children":[{"text":"Example of a ","italic":true},{"href":"https://youtu.be/zPG4NjIkCjc","type":"link","children":[{"text":"linear regression model","italic":true}],"openInNewTab":false},{"text":""}]},{"type":"paragraph","children":[{"text":"As you can see, there are plenty of ways to measure how good an algorithm is, even for the simplest versions of classifications and predictions. Therefore, it is up to the AI competition organizers to go with the one that’s the most suitable to their expectations, importance values, and the context of the problem.  Which then determines the success of the algorithm, bringing us full circle."}]},{"type":"paragraph","children":[{"text":"Sources:"}]},{"type":"paragraph","children":[{"text":""},{"href":"https://developers.google.com/machine-learning/crash-course/classification/precision-and-recall","type":"link","children":[{"text":"Precision and Recall"}],"openInNewTab":false},{"text":""}]},{"type":"paragraph","children":[{"text":""},{"href":"https://en.wikipedia.org/wiki/F-score","type":"link","children":[{"text":"F-Score"}],"openInNewTab":false},{"text":""}]},{"type":"paragraph","children":[{"text":""},{"href":"https://towardsdatascience.com/metrics-to-evaluate-your-machine-learning-algorithm-f10ba6e38234","type":"link","children":[{"text":"Performance Metrics"}],"openInNewTab":false},{"text":""}]},{"type":"paragraph","children":[{"text":""},{"href":"https://www.analyticsvidhya.com/blog/2015/08/comprehensive-guide-regression/","type":"link","children":[{"text":"Regression"}],"openInNewTab":false},{"text":""}]},{"type":"paragraph","children":[{"text":""},{"href":"https://www.science.org/doi/full/10.1126/science.331.6018.698","type":"link","children":[{"text":"Further Reading"}],"openInNewTab":false},{"text":""}]},{"type":"paragraph","children":[{"text":""}]},{"src":"https://media.graphcms.com/Po53jbTuQsKqZJOvxVii","type":"image","title":"roc-auc.png","width":1000,"handle":"Po53jbTuQsKqZJOvxVii","height":708,"children":[{"text":""}],"mimeType":"image/png"},{"type":"paragraph","children":[{"text":""}]}]}},"categories":[{"name":"Artificial Intelligence","slug":"ai"},{"name":"Life applications of AI","slug":"life-applications"}]}},"__N_SSG":true},"page":"/post/[slug]","query":{"slug":"performance-metrics"},"buildId":"TkC8NIFVtHPKqN7ziD4b1","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>